{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivorship\n",
    "## Predicting who'd survive**\n",
    "\n",
    "**URL**: https://www.kaggle.com/c/titanic/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikl\\Anaconda2\\envs\\AppliedDataScience\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv(\"../input/test.csv\")\n",
    "train_raw = pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "What does the data look like? How does each feature relate to survivorship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Age', 'Embarked', 'Fare', 'Cabin'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check for missing values, we will have to address these missing values later \n",
    "null_cols = set(train_raw.columns[train_raw.isna().any()].tolist())\n",
    "null_cols.update(test_raw.columns[test_raw.isna().any()].tolist())\n",
    "print(null_cols)\n",
    "train_raw.columns[train_raw.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    0.629630\n",
      "2    0.472826\n",
      "3    0.242363\n",
      "Name: Survived, dtype: float64 \n",
      "\n",
      "Sex\n",
      "female    0.742038\n",
      "male      0.188908\n",
      "Name: Survived, dtype: float64 \n",
      "\n",
      "Embarked\n",
      "C    0.553571\n",
      "Q    0.389610\n",
      "S    0.336957\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's first check the easier label columns \n",
    "print(train_raw['Survived'].groupby(train_raw['Pclass']).mean(), '\\n')\n",
    "print(train_raw['Survived'].groupby(train_raw['Sex']).mean(), '\\n')\n",
    "print(train_raw['Survived'].groupby(train_raw['Embarked']).mean())\n",
    "\n",
    "# We can see that Pclass, Sex, and Embarking Port were very important\n",
    "# for determining survival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Survived\n",
      "age_range          \n",
      "0-18       0.503597\n",
      "18-35      0.382682\n",
      "35-50      0.398693\n",
      "50+        0.343750\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at numeric columns, but first we must cut them\n",
    "\n",
    "def get_age_range(data):\n",
    "    bins = [0, 18, 35, 50, np.inf]\n",
    "    names = ['0-18', '18-35', '35-50', '50+']\n",
    "    return pd.cut(data['Age'], bins, labels=names)\n",
    "\n",
    "train_raw['age_range'] = get_age_range(train_raw)\n",
    "print(train_raw[['Survived','age_range']].groupby(['age_range']).mean())\n",
    "# print(train_raw[['Survived','age_range','Pclass']].groupby(['age_range','Pclass']).mean())\n",
    "\n",
    "del train_raw['age_range'] # let's clean that up \n",
    "\n",
    "# Looks like being young is an advantage to survive the titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived\n",
      "family_size          \n",
      "alone        0.303538\n",
      "large        0.161290\n",
      "small        0.578767\n"
     ]
    }
   ],
   "source": [
    "# What about your family size?\n",
    "\n",
    "def get_family_size(data):\n",
    "    return data.apply(lambda row: \n",
    "                      \"alone\" if (row[\"SibSp\"] + row[\"Parch\"]) == 0 else \"small\" \n",
    "                      if (row[\"SibSp\"] + row[\"Parch\"]) <= 3 \n",
    "                      else \"large\", axis=1 )\n",
    "\n",
    "train_raw[\"family_size\"] = get_family_size(train_raw)\n",
    "        \n",
    "\n",
    "print(train_raw[['Survived','family_size']].groupby(['family_size']).mean())\n",
    "del train_raw['family_size']\n",
    "\n",
    "# Small families had higher survival rates, followed by solo travelers, and finally large families "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Survived\n",
      "fare_range                 \n",
      "(-0.001, 7.775]    0.205128\n",
      "(7.775, 8.662]     0.190789\n",
      "(8.662, 14.454]    0.366906\n",
      "(14.454, 26.0]     0.436242\n",
      "(26.0, 52.369]     0.417808\n",
      "(52.369, 512.329]  0.697987\n"
     ]
    }
   ],
   "source": [
    "# What about Fare paid?\n",
    "\n",
    "train_raw['fare_range'] = pd.qcut(train_raw['Fare'], 6)\n",
    "print(train_raw[['Survived','fare_range']].groupby(['fare_range']).mean())\n",
    "del train_raw['fare_range']\n",
    "\n",
    "# Of course the more you paid, the richer you were, the more likely you survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Survived\n",
      "cabin_letter          \n",
      "D             0.757576\n",
      "E             0.750000\n",
      "B             0.744681\n",
      "F             0.615385\n",
      "C             0.593220\n",
      "G             0.500000\n",
      "A             0.466667\n",
      "Missing       0.299854\n",
      "T             0.000000 \n",
      "\n",
      "               Survived\n",
      "cabin_num              \n",
      "(1.999, 19.8]  0.725000\n",
      "(33.0, 52.0]   0.700000\n",
      "(19.8, 33.0]   0.682927\n",
      "(85.2, 148.0]  0.650000\n",
      "(52.0, 85.2]   0.589744\n"
     ]
    }
   ],
   "source": [
    "# For cabin, let's separate the number and letter\n",
    "\n",
    "def get_cabin_letter(data):\n",
    "    return data.apply(lambda row: \"Missing\" if str(row['Cabin'])[0] == \"n\" else str(row['Cabin'])[0], axis=1)\n",
    "\n",
    "def get_cabin_num(data):\n",
    "    raw_num = data['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    raw_num.replace('an', np.NaN, inplace = True)\n",
    "    return raw_num.apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "\n",
    "train_raw['cabin_letter'] = get_cabin_letter(train_raw)\n",
    "print(train_raw[['Survived','cabin_letter']].groupby(['cabin_letter']).mean().sort_values(by='Survived',ascending=False)\n",
    "      , '\\n')\n",
    "del train_raw['cabin_letter']\n",
    "\n",
    "# We see that D, E, B cabins had higher survival rates, and those with missing cabins had the lowest\n",
    "# But what about cabin numbers?\n",
    "\n",
    "train_raw['cabin_num'] = pd.qcut(get_cabin_num(train_raw), 5)\n",
    "print(train_raw[['Survived','cabin_num']].groupby(['cabin_num']).mean().sort_values(by='Survived',ascending=False))\n",
    "del train_raw['cabin_num']\n",
    "\n",
    "# Looks like certain cabin numbers also had higher survival rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Survived\n",
      "ticket_len          \n",
      "3           0.000000\n",
      "4           0.366337\n",
      "5           0.618321\n",
      "6           0.319809\n",
      "7           0.296296\n",
      "8           0.539474\n",
      "9           0.192308\n",
      "10          0.341463\n",
      "11          0.250000\n",
      "12          0.400000\n",
      "13          0.400000\n",
      "15          0.333333\n",
      "16          0.272727\n",
      "17          0.428571\n",
      "18          0.000000 \n",
      "\n",
      "               Survived\n",
      "ticket_letter          \n",
      "9              1.000000\n",
      "P              0.646154\n",
      "1              0.630137\n",
      "F              0.571429\n",
      "2              0.464481\n",
      "C              0.340426\n",
      "S              0.323077\n",
      "L              0.250000\n",
      "3              0.239203\n",
      "4              0.200000\n",
      "6              0.166667\n",
      "W              0.153846\n",
      "7              0.111111\n",
      "A              0.068966\n",
      "5              0.000000\n",
      "8              0.000000 \n",
      "\n",
      "               Survived\n",
      "ticket_letter          \n",
      "3                   301\n",
      "2                   183\n",
      "1                   146\n",
      "P                    65\n",
      "S                    65\n",
      "C                    47\n",
      "A                    29\n",
      "W                    13\n",
      "4                    10\n",
      "7                     9\n",
      "F                     7\n",
      "6                     6\n",
      "L                     4\n",
      "5                     3\n",
      "8                     2\n",
      "9                     1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do something similar to ticket\n",
    "def get_ticket_len(data):\n",
    "    return data.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "\n",
    "def get_ticket_letter(data):\n",
    "    return data.apply(lambda row: str(str(row['Ticket'])[0]), axis=1)\n",
    "\n",
    "def map_ticket_letter(letter):\n",
    "    if letter in ['3','2','1','S','P','C','A']:\n",
    "        return letter\n",
    "    elif letter in ['W','4','7','F','6','L','5','8','9']:\n",
    "        return \"uncommon\" \n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Does the ticket length tell us anything?\n",
    "train_raw['ticket_len'] = get_ticket_len(train_raw)\n",
    "print(train_raw[['Survived','ticket_len']].groupby(['ticket_len']).mean(), '\\n')\n",
    "del train_raw['ticket_len']\n",
    "#Looking at the results, a bit\n",
    "\n",
    "#What about the first ticket letter?\n",
    "train_raw['ticket_letter'] = get_ticket_letter(train_raw)\n",
    "print(train_raw[['Survived','ticket_letter']].groupby(['ticket_letter']).mean().sort_values(by='Survived',ascending=False), '\\n')\n",
    "#There's definitely some info here, but we may have to cut down on which ticket letter matter, by looking at the counts\n",
    "print(train_raw[['Survived','ticket_letter']].groupby(['ticket_letter']).count().sort_values(by='Survived',ascending=False), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "del train_raw['ticket_letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Survived\n",
      "title              \n",
      "the        1.000000\n",
      "Mlle.      1.000000\n",
      "Sir.       1.000000\n",
      "Ms.        1.000000\n",
      "Lady.      1.000000\n",
      "Mme.       1.000000\n",
      "Mrs.       0.792000\n",
      "Miss.      0.697802\n",
      "Master.    0.575000\n",
      "Col.       0.500000\n",
      "Major.     0.500000\n",
      "Dr.        0.428571\n",
      "Mr.        0.156673\n",
      "Jonkheer.  0.000000\n",
      "Rev.       0.000000\n",
      "Don.       0.000000\n",
      "Capt.      0.000000\n",
      "                Survived\n",
      "name_len                \n",
      "(32.0, 82.0]    0.674556\n",
      "(27.0, 32.0]    0.442424\n",
      "(23.0, 27.0]    0.319797\n",
      "(19.0, 23.0]    0.301282\n",
      "(11.999, 19.0]  0.220588\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the info we can extract from Name\n",
    "\n",
    "def get_title(data):\n",
    "    return data.apply(lambda row: row['Name'].split(\",\")[1].strip().split(\" \")[0], axis=1)\n",
    "\n",
    "def get_name_len(data):\n",
    "    return data.apply(lambda row: len(row['Name']), axis=1)\n",
    "\n",
    "# We can get the title from Name\n",
    "train_raw['title'] = get_title(train_raw)\n",
    "print(train_raw[['Survived','title']].groupby(['title']).mean().sort_values(by='Survived',ascending=False))\n",
    "del train_raw['title']\n",
    "# We can see certain nobility titles seem to have way better odds of survival\n",
    "\n",
    "# What about how long the name is?\n",
    "train_raw['name_len'] = pd.qcut(get_name_len(train_raw), 5)\n",
    "print(train_raw[['Survived','name_len']].groupby(['name_len']).mean().sort_values(by='Survived',ascending=False))\n",
    "del train_raw['name_len']\n",
    "# We see that long names have higher survival rates, maybe people with longer names were also richer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions transform our columns into the final form we need them in \n",
    "def trans_name(train, test):\n",
    "    for data in [train, test]:\n",
    "            data[\"title\"] = get_title(data)\n",
    "            data[\"name_len\"] = get_name_len(data)\n",
    "            del data[\"Name\"]\n",
    "    return train,test\n",
    "\n",
    "def trans_age(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"age_missing\"] = data.apply(lambda row: 1 if row['Age'] != row['Age'] else 0, axis=1)\n",
    "        newAges = train.groupby(['title', 'Pclass'])['Age']\n",
    "        data['Age'] = newAges.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train,test\n",
    "    \n",
    "def trans_ticket(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"ticket_len\"] = get_ticket_len(data)\n",
    "        data[\"ticket_letter\"] = get_ticket_letter(data)\n",
    "        data[\"ticket_letter\"] = data.apply(lambda row: map_ticket_letter(row['ticket_letter']), axis=1)\n",
    "        del data['Ticket']\n",
    "    return train, test\n",
    "\n",
    "def trans_family(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"family_size\"] = get_family_size(data)\n",
    "        del data[\"SibSp\"]\n",
    "        del data[\"Parch\"]\n",
    "    return train,test\n",
    "\n",
    "def trans_fare(train, test):\n",
    "    mean = train['Fare'].mean()    \n",
    "    train['Fare'].fillna(mean, inplace=True) \n",
    "    test['Fare'].fillna(mean, inplace=True) \n",
    "    return train,test\n",
    "\n",
    "def trans_embarked(train, test):\n",
    "    train['Embarked'] = train['Embarked'].fillna(\"S\") \n",
    "    test['Embarked'] = test['Embarked'].fillna(\"S\") \n",
    "    return train,test\n",
    "\n",
    "def trans_cabin(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"cabin_missing\"] = data.apply(lambda row: 0 if row['Cabin'] == row['Cabin'] else 1, axis=1)\n",
    "        data[\"cabin_letter\"] = get_cabin_letter(data)\n",
    "        data[\"cabin_num1\"] = get_cabin_num(data)\n",
    "        data['cabin_num'] = pd.qcut(train['cabin_num1'],5)\n",
    "    \n",
    "    train = pd.concat((train, pd.get_dummies(train['cabin_num'], prefix = 'cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['cabin_num'], prefix = 'cabin_num')), axis = 1)\n",
    "    del train['cabin_num']\n",
    "    del test['cabin_num']\n",
    "    del train['cabin_num1']\n",
    "    del test['cabin_num1']\n",
    "    del test['Cabin']\n",
    "    del train['Cabin']\n",
    "    return train, test\n",
    "\n",
    "def get_dummies(train, test):\n",
    "    cols_to_expand = ['Sex','Embarked', 'Pclass', 'title', 'cabin_letter','family_size', 'ticket_letter']\n",
    "    for column in cols_to_expand:\n",
    "        vals = set(train[column].unique())\n",
    "        vals = vals.intersection(set(test[column].unique()))\n",
    "        new_cols = [column + \"_\" + str(val) for val in vals]\n",
    "\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[new_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[new_cols]), axis = 1)\n",
    "    \n",
    "        del train[column]\n",
    "        del test[column]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, test, cols):\n",
    "    cols = list(train.columns)\n",
    "    cols.remove(\"PassengerId\")\n",
    "    cols.remove(\"Survived\")\n",
    "    all_cols = get_cols_by_type(test[cols])\n",
    "    num_cols = all_cols['int64']\n",
    "    num_cols.extend(all_cols['float64'])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = train.copy()\n",
    "    X_test = test.copy()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  48\n",
      "Any Nulls:  False False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>name_len</th>\n",
       "      <th>age_missing</th>\n",
       "      <th>ticket_len</th>\n",
       "      <th>cabin_missing</th>\n",
       "      <th>cabin_num_(1.999, 19.8]</th>\n",
       "      <th>cabin_num_(19.8, 33.0]</th>\n",
       "      <th>cabin_num_(33.0, 52.0]</th>\n",
       "      <th>cabin_num_(52.0, 85.2]</th>\n",
       "      <th>cabin_num_(85.2, 148.0]</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>title_Col.</th>\n",
       "      <th>title_Rev.</th>\n",
       "      <th>title_Ms.</th>\n",
       "      <th>title_Miss.</th>\n",
       "      <th>title_Mr.</th>\n",
       "      <th>title_Master.</th>\n",
       "      <th>title_Dr.</th>\n",
       "      <th>title_Mrs.</th>\n",
       "      <th>cabin_letter_B</th>\n",
       "      <th>cabin_letter_D</th>\n",
       "      <th>cabin_letter_A</th>\n",
       "      <th>cabin_letter_F</th>\n",
       "      <th>cabin_letter_Missing</th>\n",
       "      <th>cabin_letter_E</th>\n",
       "      <th>cabin_letter_G</th>\n",
       "      <th>cabin_letter_C</th>\n",
       "      <th>family_size_small</th>\n",
       "      <th>family_size_alone</th>\n",
       "      <th>family_size_large</th>\n",
       "      <th>ticket_letter_S</th>\n",
       "      <th>ticket_letter_uncommon</th>\n",
       "      <th>ticket_letter_3</th>\n",
       "      <th>ticket_letter_A</th>\n",
       "      <th>ticket_letter_P</th>\n",
       "      <th>ticket_letter_2</th>\n",
       "      <th>ticket_letter_1</th>\n",
       "      <th>ticket_letter_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived   Age     Fare  name_len  age_missing  ticket_len  \\\n",
       "0            1         0  22.0   7.2500        23            0           9   \n",
       "1            2         1  38.0  71.2833        51            0           8   \n",
       "2            3         1  26.0   7.9250        22            0          16   \n",
       "3            4         1  35.0  53.1000        44            0           6   \n",
       "4            5         0  35.0   8.0500        24            0           6   \n",
       "\n",
       "   cabin_missing  cabin_num_(1.999, 19.8]  cabin_num_(19.8, 33.0]  \\\n",
       "0              1                        0                       0   \n",
       "1              0                        0                       0   \n",
       "2              1                        0                       0   \n",
       "3              0                        0                       0   \n",
       "4              1                        0                       0   \n",
       "\n",
       "   cabin_num_(33.0, 52.0]  cabin_num_(52.0, 85.2]  cabin_num_(85.2, 148.0]  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       1                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       0                        1   \n",
       "4                       0                       0                        0   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_S  Embarked_C  Embarked_Q  Pclass_1  \\\n",
       "0           0         1           1           0           0         0   \n",
       "1           1         0           0           1           0         1   \n",
       "2           1         0           1           0           0         0   \n",
       "3           1         0           1           0           0         1   \n",
       "4           0         1           1           0           0         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  title_Col.  title_Rev.  title_Ms.  title_Miss.  \\\n",
       "0         0         1           0           0          0            0   \n",
       "1         0         0           0           0          0            0   \n",
       "2         0         1           0           0          0            1   \n",
       "3         0         0           0           0          0            0   \n",
       "4         0         1           0           0          0            0   \n",
       "\n",
       "   title_Mr.  title_Master.  title_Dr.  title_Mrs.  cabin_letter_B  \\\n",
       "0          1              0          0           0               0   \n",
       "1          0              0          0           1               0   \n",
       "2          0              0          0           0               0   \n",
       "3          0              0          0           1               0   \n",
       "4          1              0          0           0               0   \n",
       "\n",
       "   cabin_letter_D  cabin_letter_A  cabin_letter_F  cabin_letter_Missing  \\\n",
       "0               0               0               0                     1   \n",
       "1               0               0               0                     0   \n",
       "2               0               0               0                     1   \n",
       "3               0               0               0                     0   \n",
       "4               0               0               0                     1   \n",
       "\n",
       "   cabin_letter_E  cabin_letter_G  cabin_letter_C  family_size_small  \\\n",
       "0               0               0               0                  1   \n",
       "1               0               0               1                  1   \n",
       "2               0               0               0                  0   \n",
       "3               0               0               1                  1   \n",
       "4               0               0               0                  0   \n",
       "\n",
       "   family_size_alone  family_size_large  ticket_letter_S  \\\n",
       "0                  0                  0                0   \n",
       "1                  0                  0                0   \n",
       "2                  1                  0                1   \n",
       "3                  0                  0                0   \n",
       "4                  1                  0                0   \n",
       "\n",
       "   ticket_letter_uncommon  ticket_letter_3  ticket_letter_A  ticket_letter_P  \\\n",
       "0                       0                0                1                0   \n",
       "1                       0                0                0                1   \n",
       "2                       0                0                0                0   \n",
       "3                       0                0                0                0   \n",
       "4                       0                1                0                0   \n",
       "\n",
       "   ticket_letter_2  ticket_letter_1  ticket_letter_C  \n",
       "0                0                0                0  \n",
       "1                0                0                0  \n",
       "2                0                0                0  \n",
       "3                0                1                0  \n",
       "4                0                0                0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_raw.copy()\n",
    "test = test_raw.copy()\n",
    "\n",
    "train, test = trans_name(train, test)\n",
    "train, test = trans_age(train, test)  \n",
    "train, test = trans_ticket(train, test)\n",
    "train, test = trans_family(train, test)\n",
    "train, test = trans_fare(train, test)\n",
    "train, test = trans_embarked(train, test)\n",
    "train, test = trans_cabin(train, test)\n",
    "train, test = get_dummies(train, test)\n",
    "train, test = scale_data(train, test, list(train.columns))\n",
    "\n",
    "print(\"Columns: \", len(train.columns))\n",
    "cols = list(train.columns[2:]) # features relevant to our ML model\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# train[cols] = scaler.fit_transform(train[cols])\n",
    "# test[cols] = scaler.transform(test[cols])\n",
    "\n",
    "print(\"Any Nulls: \", train.isnull().values.any(), test.isnull().values.any())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these functions to select the best features from our data\n",
    "def select_cols(feature_cols, target, data, k):\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_new = selector.fit_transform(data[feature_cols], data[target]) \n",
    "\n",
    "    selected_features = pd.DataFrame(selector.inverse_transform(X_new), index=data.index, columns=feature_cols)\n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "    return selected_columns\n",
    "    \n",
    "def find_best_cols(cols, target, data):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    state = 1993  \n",
    "    size = 0.30 \n",
    "   \n",
    "    X_train = data[:1000]\n",
    "    X_valid = data[1000:]\n",
    "    \n",
    "    lr = ensemble.GradientBoostingRegressor() #Base Model\n",
    "    lr.fit(X_train[cols], X_train[target].values.ravel())\n",
    "    print (\"Base Score: \", lr.score(X_train[cols], X_train[target].values.ravel())) # 0.9672992360887501\n",
    "    best_score = 0\n",
    "    best_cols = cols\n",
    "    for k in range(len(cols)//4, len(cols)):\n",
    "        lr = ensemble.GradientBoostingRegressor()\n",
    "        curr_cols = select_cols(cols, target, X_train, k)\n",
    "        lr.fit(X_train[curr_cols], X_train[target].values.ravel())\n",
    "        os_score = lr.score(X_valid[curr_cols], X_valid[target].values.ravel())\n",
    "        if os_score > best_score:\n",
    "            is_score = lr.score(X_train[curr_cols], X_train[target].values.ravel())\n",
    "            print (\"K= \", k, \", IS score: \", is_score, \", OS score: \", os_score) # 0.840628507295174\n",
    "            best_score = os_score\n",
    "            best_cols = curr_cols\n",
    "            \n",
    "    return best_cols\n",
    "\n",
    "best_cols = find_best_cols(cols, \"SalePrice\", train)\n",
    "best_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(best_cols))\n",
    "print(len(cols))\n",
    "cols = best_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this function to save our results to CSV\n",
    "def save_results(model, data):\n",
    "    pred_test = model.predict(data)\n",
    "\n",
    "    #PassengerId,Survived\n",
    "    test_res = test[[\"PassengerId\"]].copy()\n",
    "    test_res[\"Survived\"] = pred_test\n",
    "    test_res.to_csv(\"my_predictions.csv\", index=False)\n",
    "    return test_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use this function to tune our model\n",
    "def get_tuned_model(estimator, param_grid, scoring, X_train, Y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid = GridSearchCV(estimator = estimator, \n",
    "                       param_grid = param_grid,\n",
    "                       scoring = scoring,\n",
    "                       cv=3,\n",
    "                       n_jobs= -1\n",
    "                      )\n",
    "\n",
    "    tuned = grid.fit(X_train, Y_train)\n",
    "\n",
    "    print (\"Best score: \", tuned.best_score_) # 0.840628507295174\n",
    "    print (\"Best params: \", tuned.best_params_)\n",
    "    print (\"IS Score: \", tuned.score(X_train, Y_train)) # 0.8698092031425365\n",
    "    \n",
    "    return tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8316427091833531\n",
      "Best params:  {'C': 0.1, 'max_iter': 100, 'penalty': 'l2'}\n",
      "IS Score:  0.8439955106621774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erikl\\Anaconda2\\envs\\AppliedDataScience\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty': ['l1','l2'], \n",
    "              'C': [0.001,0.01,0.1,1,10,100],\n",
    "              'max_iter': [100,200,300,500]\n",
    "             }\n",
    "\n",
    "log_tuned = get_tuned_model(logit, param_grid, \"accuracy\", train[cols], train[['Survived']].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(log_tuned, test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8293955181721173\n",
      "Best params:  {'criterion': 'gini', 'max_leaf_nodes': 14, 'min_samples_leaf': 1}\n",
      "IS Score:  0.856341189674523\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    \"criterion\" : [\"gini\", \"entropy\"], \n",
    "    \"min_samples_leaf\" : [1, 5, 10], \n",
    "#     \"min_samples_split\" : [2, 4, 10, 12, 16],\n",
    "#     \"n_estimators\": n_estimators,\n",
    "    'max_leaf_nodes': range(2,20)\n",
    "}\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "ft_tuned = get_tuned_model(forest, param_grid, \"accuracy\", train[cols], train[['Survived']].values.ravel())\n",
    "# best 0.840628507295174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ft_tuned, test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.857447743393384\n",
      "Best params:  {'learning_rate': 0.1, 'max_features': 15, 'n_estimators': 500}\n",
      "IS Score:  0.9685746352413019\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    \"learning_rate\":  [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "    \"n_estimators\": [8, 16, 32, 64, 100, 200, 400, 500],\n",
    "#     'subsample':[0.5, 0.6, 0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "    'max_features': list(range(len(cols)//4,len(cols)//2)),\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc_tuned = get_tuned_model(gbc, param_grid, \"accuracy\", train[cols], train[['Survived']].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(gbc_tuned, test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
