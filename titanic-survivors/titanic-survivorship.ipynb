{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivorship\n",
    "## Predicting who'd survive\n",
    "\n",
    "**URL**: https://www.kaggle.com/c/titanic/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv(\"../data//test.csv\")\n",
    "train_raw = pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "What does the data look like? How does each feature relate to survivorship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Embarked', 'Age', 'Cabin', 'Fare'}\n"
     ]
    }
   ],
   "source": [
    "# Let's check for missing values, we will have to address these missing values later \n",
    "null_cols = set(train_raw.columns[train_raw.isna().any()].tolist())\n",
    "null_cols.update(test_raw.columns[test_raw.isna().any()].tolist())\n",
    "print(null_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "1    0.629630\n",
      "2    0.472826\n",
      "3    0.242363\n",
      "Name: Survived, dtype: float64 \n",
      "\n",
      "Sex\n",
      "female    0.742038\n",
      "male      0.188908\n",
      "Name: Survived, dtype: float64 \n",
      "\n",
      "Embarked\n",
      "C    0.553571\n",
      "Q    0.389610\n",
      "S    0.336957\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Let's first check the easier label columns \n",
    "print(train_raw['Survived'].groupby(train_raw['Pclass']).mean(), '\\n')\n",
    "print(train_raw['Survived'].groupby(train_raw['Sex']).mean(), '\\n')\n",
    "print(train_raw['Survived'].groupby(train_raw['Embarked']).mean())\n",
    "\n",
    "# We can see that Pclass, Sex, and Embarking Port were very important\n",
    "# for determining survival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Survived\n",
      "age_range          \n",
      "0-18       0.503597\n",
      "18-35      0.382682\n",
      "35-50      0.398693\n",
      "50+        0.343750\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at numeric columns, but first we must cut them\n",
    "def get_age_range(data):\n",
    "    bins = [0, 18, 35, 50, np.inf]\n",
    "    names = ['0-18', '18-35', '35-50', '50+']\n",
    "    return pd.cut(data['Age'], bins, labels=names)\n",
    "\n",
    "train_raw['age_range'] = get_age_range(train_raw)\n",
    "print(train_raw[['Survived','age_range']].groupby(['age_range']).mean())\n",
    "# print(train_raw[['Survived','age_range','Pclass']].groupby(['age_range','Pclass']).mean())\n",
    "\n",
    "del train_raw['age_range'] # let's clean that up \n",
    "\n",
    "# Looks like being young is an advantage to survive the titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived\n",
      "family_size          \n",
      "alone        0.303538\n",
      "large        0.161290\n",
      "small        0.578767\n"
     ]
    }
   ],
   "source": [
    "# What about your family size?\n",
    "\n",
    "def get_family_size(data):\n",
    "    return data.apply(lambda row: \n",
    "                      \"alone\" if (row[\"SibSp\"] + row[\"Parch\"]) == 0 else \"small\" \n",
    "                      if (row[\"SibSp\"] + row[\"Parch\"]) <= 3 \n",
    "                      else \"large\", axis=1 )\n",
    "\n",
    "train_raw[\"family_size\"] = get_family_size(train_raw)\n",
    "        \n",
    "\n",
    "print(train_raw[['Survived','family_size']].groupby(['family_size']).mean())\n",
    "del train_raw['family_size']\n",
    "\n",
    "# Small families had higher survival rates, followed by solo travelers, and finally large families "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Survived\n",
      "fare_range                 \n",
      "(-0.001, 7.775]    0.205128\n",
      "(7.775, 8.662]     0.190789\n",
      "(8.662, 14.454]    0.366906\n",
      "(14.454, 26.0]     0.436242\n",
      "(26.0, 52.369]     0.417808\n",
      "(52.369, 512.329]  0.697987\n"
     ]
    }
   ],
   "source": [
    "# What about Fare paid?\n",
    "\n",
    "train_raw['fare_range'] = pd.qcut(train_raw['Fare'], 6)\n",
    "print(train_raw[['Survived','fare_range']].groupby(['fare_range']).mean())\n",
    "del train_raw['fare_range']\n",
    "\n",
    "# Of course the more you paid, the richer you were, the more likely you survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Survived\n",
      "cabin_letter          \n",
      "D             0.757576\n",
      "E             0.750000\n",
      "B             0.744681\n",
      "F             0.615385\n",
      "C             0.593220\n",
      "G             0.500000\n",
      "A             0.466667\n",
      "Missing       0.299854\n",
      "T             0.000000 \n",
      "\n",
      "               Survived\n",
      "cabin_num              \n",
      "(1.999, 19.8]  0.725000\n",
      "(33.0, 52.0]   0.700000\n",
      "(19.8, 33.0]   0.682927\n",
      "(85.2, 148.0]  0.650000\n",
      "(52.0, 85.2]   0.589744\n"
     ]
    }
   ],
   "source": [
    "# For cabin, let's separate the number and letter\n",
    "\n",
    "def get_cabin_letter(data):\n",
    "    return data.apply(lambda row: \"Missing\" if str(row['Cabin'])[0] == \"n\" else str(row['Cabin'])[0], axis=1)\n",
    "\n",
    "def get_cabin_num(data):\n",
    "    raw_num = data['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    raw_num.replace('an', np.NaN, inplace = True)\n",
    "    return raw_num.apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "\n",
    "train_raw['cabin_letter'] = get_cabin_letter(train_raw)\n",
    "print(train_raw[['Survived','cabin_letter']].groupby(['cabin_letter']).mean().sort_values(by='Survived',ascending=False)\n",
    "      , '\\n')\n",
    "del train_raw['cabin_letter']\n",
    "\n",
    "# We see that D, E, B cabins had higher survival rates, and those with missing cabins had the lowest\n",
    "# But what about cabin numbers?\n",
    "\n",
    "train_raw['cabin_num'] = pd.qcut(get_cabin_num(train_raw), 5)\n",
    "print(train_raw[['Survived','cabin_num']].groupby(['cabin_num']).mean().sort_values(by='Survived',ascending=False))\n",
    "del train_raw['cabin_num']\n",
    "\n",
    "# Looks like certain cabin numbers also had higher survival rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Survived\n",
      "ticket_len          \n",
      "3           0.000000\n",
      "4           0.366337\n",
      "5           0.618321\n",
      "6           0.319809\n",
      "7           0.296296\n",
      "8           0.539474\n",
      "9           0.192308\n",
      "10          0.341463\n",
      "11          0.250000\n",
      "12          0.400000\n",
      "13          0.400000\n",
      "15          0.333333\n",
      "16          0.272727\n",
      "17          0.428571\n",
      "18          0.000000 \n",
      "\n",
      "               Survived\n",
      "ticket_letter          \n",
      "9              1.000000\n",
      "P              0.646154\n",
      "1              0.630137\n",
      "F              0.571429\n",
      "2              0.464481\n",
      "C              0.340426\n",
      "S              0.323077\n",
      "L              0.250000\n",
      "3              0.239203\n",
      "4              0.200000\n",
      "6              0.166667\n",
      "W              0.153846\n",
      "7              0.111111\n",
      "A              0.068966\n",
      "5              0.000000\n",
      "8              0.000000 \n",
      "\n",
      "               Survived\n",
      "ticket_letter          \n",
      "3                   301\n",
      "2                   183\n",
      "1                   146\n",
      "P                    65\n",
      "S                    65\n",
      "C                    47\n",
      "A                    29\n",
      "W                    13\n",
      "4                    10\n",
      "7                     9\n",
      "F                     7\n",
      "6                     6\n",
      "L                     4\n",
      "5                     3\n",
      "8                     2\n",
      "9                     1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do something similar to ticket\n",
    "def get_ticket_len(data):\n",
    "    return data.apply(lambda row: len(row['Ticket']), axis=1)\n",
    "\n",
    "def get_ticket_letter(data):\n",
    "    return data.apply(lambda row: str(str(row['Ticket'])[0]), axis=1)\n",
    "\n",
    "def map_ticket_letter(letter):\n",
    "    if letter in ['3','2','1','S','P','C','A']:\n",
    "        return letter\n",
    "    elif letter in ['W','4','7','F','6','L','5','8','9']:\n",
    "        return \"uncommon\" \n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Does the ticket length tell us anything?\n",
    "train_raw['ticket_len'] = get_ticket_len(train_raw)\n",
    "print(train_raw[['Survived','ticket_len']].groupby(['ticket_len']).mean(), '\\n')\n",
    "del train_raw['ticket_len']\n",
    "#Looking at the results, a bit\n",
    "\n",
    "#What about the first ticket letter?\n",
    "train_raw['ticket_letter'] = get_ticket_letter(train_raw)\n",
    "print(train_raw[['Survived','ticket_letter']].groupby(['ticket_letter']).mean().sort_values(by='Survived',ascending=False), '\\n')\n",
    "#There's definitely some info here, but we may have to cut down on which ticket letter matter, by looking at the counts\n",
    "print(train_raw[['Survived','ticket_letter']].groupby(['ticket_letter']).count().sort_values(by='Survived',ascending=False), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "del train_raw['ticket_letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Survived\n",
      "title              \n",
      "the        1.000000\n",
      "Mlle.      1.000000\n",
      "Sir.       1.000000\n",
      "Ms.        1.000000\n",
      "Lady.      1.000000\n",
      "Mme.       1.000000\n",
      "Mrs.       0.792000\n",
      "Miss.      0.697802\n",
      "Master.    0.575000\n",
      "Col.       0.500000\n",
      "Major.     0.500000\n",
      "Dr.        0.428571\n",
      "Mr.        0.156673\n",
      "Jonkheer.  0.000000\n",
      "Rev.       0.000000\n",
      "Don.       0.000000\n",
      "Capt.      0.000000\n",
      "                Survived\n",
      "name_len                \n",
      "(32.0, 82.0]    0.674556\n",
      "(27.0, 32.0]    0.442424\n",
      "(23.0, 27.0]    0.319797\n",
      "(19.0, 23.0]    0.301282\n",
      "(11.999, 19.0]  0.220588\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the info we can extract from Name\n",
    "\n",
    "def get_title(data):\n",
    "    return data.apply(lambda row: row['Name'].split(\",\")[1].strip().split(\" \")[0], axis=1)\n",
    "\n",
    "def get_name_len(data):\n",
    "    return data.apply(lambda row: len(row['Name']), axis=1)\n",
    "\n",
    "# We can get the title from Name\n",
    "train_raw['title'] = get_title(train_raw)\n",
    "print(train_raw[['Survived','title']].groupby(['title']).mean().sort_values(by='Survived',ascending=False))\n",
    "del train_raw['title']\n",
    "# We can see certain nobility titles seem to have way better odds of survival\n",
    "\n",
    "# What about how long the name is?\n",
    "train_raw['name_len'] = pd.qcut(get_name_len(train_raw), 5)\n",
    "print(train_raw[['Survived','name_len']].groupby(['name_len']).mean().sort_values(by='Survived',ascending=False))\n",
    "del train_raw['name_len']\n",
    "# We see that long names have higher survival rates, maybe people with longer names were also richer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions transform our columns into the final form we need them in \n",
    "def trans_name(train, test):\n",
    "    for data in [train, test]:\n",
    "            data[\"title\"] = get_title(data)\n",
    "            data[\"name_len\"] = get_name_len(data)\n",
    "            del data[\"Name\"]\n",
    "    return train,test\n",
    "\n",
    "def trans_age(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"age_missing\"] = data.apply(lambda row: 1 if row['Age'] != row['Age'] else 0, axis=1)\n",
    "        newAges = train.groupby(['title', 'Pclass'])['Age']\n",
    "        data['Age'] = newAges.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train,test\n",
    "    \n",
    "def trans_ticket(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"ticket_len\"] = get_ticket_len(data)\n",
    "        data[\"ticket_letter\"] = get_ticket_letter(data)\n",
    "        data[\"ticket_letter\"] = data.apply(lambda row: map_ticket_letter(row['ticket_letter']), axis=1)\n",
    "        del data['Ticket']\n",
    "    return train, test\n",
    "\n",
    "def trans_family(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"family_size\"] = get_family_size(data)\n",
    "        del data[\"SibSp\"]\n",
    "        del data[\"Parch\"]\n",
    "    return train,test\n",
    "\n",
    "def trans_fare(train, test):\n",
    "    mean = train['Fare'].mean()    \n",
    "    train['Fare'].fillna(mean, inplace=True) \n",
    "    test['Fare'].fillna(mean, inplace=True) \n",
    "    return train,test\n",
    "\n",
    "def trans_embarked(train, test):\n",
    "    train['Embarked'] = train['Embarked'].fillna(\"S\") \n",
    "    test['Embarked'] = test['Embarked'].fillna(\"S\") \n",
    "    return train,test\n",
    "\n",
    "def trans_cabin(train, test):\n",
    "    for data in [train, test]:\n",
    "        data[\"cabin_missing\"] = data.apply(lambda row: 0 if row['Cabin'] == row['Cabin'] else 1, axis=1)\n",
    "        data[\"cabin_letter\"] = get_cabin_letter(data)\n",
    "        data[\"cabin_num1\"] = get_cabin_num(data)\n",
    "        data['cabin_num'] = pd.qcut(train['cabin_num1'],5)\n",
    "    \n",
    "    train = pd.concat((train, pd.get_dummies(train['cabin_num'], prefix = 'cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['cabin_num'], prefix = 'cabin_num')), axis = 1)\n",
    "    del train['cabin_num']\n",
    "    del test['cabin_num']\n",
    "    del train['cabin_num1']\n",
    "    del test['cabin_num1']\n",
    "    del test['Cabin']\n",
    "    del train['Cabin']\n",
    "    return train, test\n",
    "\n",
    "def get_dummies(train, test):\n",
    "    cols_to_expand = ['Sex','Embarked', 'Pclass', 'title', 'cabin_letter','family_size', 'ticket_letter']\n",
    "    for column in cols_to_expand:\n",
    "        vals = set(train[column].unique())\n",
    "        vals = vals.intersection(set(test[column].unique()))\n",
    "        new_cols = [column + \"_\" + str(val) for val in vals]\n",
    "\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[new_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[new_cols]), axis = 1)\n",
    "    \n",
    "        del train[column]\n",
    "        del test[column]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_by_type(data):\n",
    "    colsbytype = {}\n",
    "    for idx, val in zip(data.dtypes.index, data.dtypes.values):\n",
    "        if idx == 'Survived':\n",
    "            continue\n",
    "        val = str(val)\n",
    "        curr = colsbytype.get(val, set())\n",
    "        curr.add(idx)\n",
    "        colsbytype[val] = curr\n",
    "    for key in colsbytype.keys():\n",
    "        columns = list(colsbytype[key])\n",
    "        columns.sort()\n",
    "        colsbytype[key] = columns\n",
    "    return colsbytype\n",
    "\n",
    "def scale_data(train, test, cols):\n",
    "    cols = list(train.columns)\n",
    "    cols.remove(\"PassengerId\")\n",
    "    cols.remove(\"Survived\")\n",
    "    all_cols = get_cols_by_type(test[cols])\n",
    "    num_cols = all_cols['int64']\n",
    "    num_cols.extend(all_cols['float64'])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = train.copy()\n",
    "    X_test = test.copy()\n",
    "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  48\n",
      "Any Nulls:  False False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>name_len</th>\n",
       "      <th>age_missing</th>\n",
       "      <th>ticket_len</th>\n",
       "      <th>cabin_missing</th>\n",
       "      <th>cabin_num_(1.999, 19.8]</th>\n",
       "      <th>cabin_num_(19.8, 33.0]</th>\n",
       "      <th>cabin_num_(33.0, 52.0]</th>\n",
       "      <th>cabin_num_(52.0, 85.2]</th>\n",
       "      <th>cabin_num_(85.2, 148.0]</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>title_Rev.</th>\n",
       "      <th>title_Mr.</th>\n",
       "      <th>title_Ms.</th>\n",
       "      <th>title_Mrs.</th>\n",
       "      <th>title_Master.</th>\n",
       "      <th>title_Dr.</th>\n",
       "      <th>title_Miss.</th>\n",
       "      <th>title_Col.</th>\n",
       "      <th>cabin_letter_Missing</th>\n",
       "      <th>cabin_letter_B</th>\n",
       "      <th>cabin_letter_D</th>\n",
       "      <th>cabin_letter_F</th>\n",
       "      <th>cabin_letter_A</th>\n",
       "      <th>cabin_letter_E</th>\n",
       "      <th>cabin_letter_C</th>\n",
       "      <th>cabin_letter_G</th>\n",
       "      <th>family_size_large</th>\n",
       "      <th>family_size_alone</th>\n",
       "      <th>family_size_small</th>\n",
       "      <th>ticket_letter_S</th>\n",
       "      <th>ticket_letter_P</th>\n",
       "      <th>ticket_letter_2</th>\n",
       "      <th>ticket_letter_1</th>\n",
       "      <th>ticket_letter_A</th>\n",
       "      <th>ticket_letter_C</th>\n",
       "      <th>ticket_letter_uncommon</th>\n",
       "      <th>ticket_letter_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived       Age      Fare  name_len  age_missing  \\\n",
       "0            1         0  0.271174  0.014151  0.157143          0.0   \n",
       "1            2         1  0.472229  0.139136  0.557143          0.0   \n",
       "2            3         1  0.321438  0.015469  0.142857          0.0   \n",
       "3            4         1  0.434531  0.103644  0.457143          0.0   \n",
       "4            5         0  0.434531  0.015713  0.171429          0.0   \n",
       "\n",
       "   ticket_len  cabin_missing  cabin_num_(1.999, 19.8]  cabin_num_(19.8, 33.0]  \\\n",
       "0    0.400000            1.0                        0                       0   \n",
       "1    0.333333            0.0                        0                       0   \n",
       "2    0.866667            1.0                        0                       0   \n",
       "3    0.200000            0.0                        0                       0   \n",
       "4    0.200000            1.0                        0                       0   \n",
       "\n",
       "   cabin_num_(33.0, 52.0]  cabin_num_(52.0, 85.2]  cabin_num_(85.2, 148.0]  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       1                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       0                        1   \n",
       "4                       0                       0                        0   \n",
       "\n",
       "   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  \\\n",
       "0           0         1           0           0           1         0   \n",
       "1           1         0           1           0           0         1   \n",
       "2           1         0           0           0           1         0   \n",
       "3           1         0           0           0           1         1   \n",
       "4           0         1           0           0           1         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  title_Rev.  title_Mr.  title_Ms.  title_Mrs.  \\\n",
       "0         0         1           0          1          0           0   \n",
       "1         0         0           0          0          0           1   \n",
       "2         0         1           0          0          0           0   \n",
       "3         0         0           0          0          0           1   \n",
       "4         0         1           0          1          0           0   \n",
       "\n",
       "   title_Master.  title_Dr.  title_Miss.  title_Col.  cabin_letter_Missing  \\\n",
       "0              0          0            0           0                     1   \n",
       "1              0          0            0           0                     0   \n",
       "2              0          0            1           0                     1   \n",
       "3              0          0            0           0                     0   \n",
       "4              0          0            0           0                     1   \n",
       "\n",
       "   cabin_letter_B  cabin_letter_D  cabin_letter_F  cabin_letter_A  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   cabin_letter_E  cabin_letter_C  cabin_letter_G  family_size_large  \\\n",
       "0               0               0               0                  0   \n",
       "1               0               1               0                  0   \n",
       "2               0               0               0                  0   \n",
       "3               0               1               0                  0   \n",
       "4               0               0               0                  0   \n",
       "\n",
       "   family_size_alone  family_size_small  ticket_letter_S  ticket_letter_P  \\\n",
       "0                  0                  1                0                0   \n",
       "1                  0                  1                0                1   \n",
       "2                  1                  0                1                0   \n",
       "3                  0                  1                0                0   \n",
       "4                  1                  0                0                0   \n",
       "\n",
       "   ticket_letter_2  ticket_letter_1  ticket_letter_A  ticket_letter_C  \\\n",
       "0                0                0                1                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   ticket_letter_uncommon  ticket_letter_3  \n",
       "0                       0                0  \n",
       "1                       0                0  \n",
       "2                       0                0  \n",
       "3                       0                0  \n",
       "4                       0                1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_raw.copy()\n",
    "test = test_raw.copy()\n",
    "\n",
    "train, test = trans_name(train, test)\n",
    "train, test = trans_age(train, test)  \n",
    "train, test = trans_ticket(train, test)\n",
    "train, test = trans_family(train, test)\n",
    "train, test = trans_fare(train, test)\n",
    "train, test = trans_embarked(train, test)\n",
    "train, test = trans_cabin(train, test)\n",
    "train, test = get_dummies(train, test)\n",
    "train, test = scale_data(train, test, list(train.columns))\n",
    "\n",
    "print(\"Columns: \", len(train.columns))\n",
    "cols = list(train.columns[2:]) # features relevant to our ML model\n",
    "\n",
    "print(\"Any Nulls: \", train.isnull().values.any(), test.isnull().values.any())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Score:  0.7307146266371403\n",
      "K=  11 , IS score:  0.6778174980269249 , OS score:  0.38011473230928355\n",
      "K=  14 , IS score:  0.6799038830124995 , OS score:  0.38521828516010104\n",
      "K=  16 , IS score:  0.6815926245577293 , OS score:  0.39747189414153655\n",
      "K=  17 , IS score:  0.687273560685436 , OS score:  0.3987086304273373\n",
      "K=  18 , IS score:  0.6922006098804987 , OS score:  0.4027129452986077\n",
      "K=  19 , IS score:  0.6957891716668709 , OS score:  0.40481317982565695\n",
      "K=  20 , IS score:  0.6800452746555953 , OS score:  0.4083569877725983\n",
      "K=  22 , IS score:  0.6784406511895433 , OS score:  0.4271823867416118\n",
      "K=  24 , IS score:  0.7326636054167353 , OS score:  0.43944665148423073\n",
      "K=  26 , IS score:  0.7262764454347781 , OS score:  0.43984874617991854\n",
      "K=  27 , IS score:  0.7283355217487086 , OS score:  0.4420982121025523\n",
      "K=  28 , IS score:  0.7283355217487086 , OS score:  0.44220392798904007\n",
      "K=  29 , IS score:  0.7255612715304716 , OS score:  0.4618329138660316\n",
      "K=  31 , IS score:  0.7309949992728819 , OS score:  0.47128218184380555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Fare', 'name_len', 'cabin_missing', 'cabin_num_(1.999, 19.8]',\n",
       "       'cabin_num_(33.0, 52.0]', 'cabin_num_(52.0, 85.2]', 'Sex_female',\n",
       "       'Sex_male', 'Embarked_C', 'Embarked_S', 'Pclass_1', 'Pclass_2',\n",
       "       'Pclass_3', 'title_Mr.', 'title_Mrs.', 'title_Miss.',\n",
       "       'cabin_letter_Missing', 'cabin_letter_B', 'cabin_letter_D',\n",
       "       'cabin_letter_F', 'cabin_letter_E', 'cabin_letter_C',\n",
       "       'family_size_large', 'family_size_alone', 'family_size_small',\n",
       "       'ticket_letter_P', 'ticket_letter_2', 'ticket_letter_1',\n",
       "       'ticket_letter_A', 'ticket_letter_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use these functions to select the best features from our data\n",
    "def select_cols(feature_cols, target, data, k):\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_new = selector.fit_transform(data[feature_cols], data[target]) \n",
    "\n",
    "    selected_features = pd.DataFrame(selector.inverse_transform(X_new), index=data.index, columns=feature_cols)\n",
    "    selected_columns = selected_features.columns[selected_features.var() != 0]\n",
    "    return selected_columns\n",
    "    \n",
    "def find_best_cols(cols, target, data):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    state = 1993  \n",
    "    size = 0.30 \n",
    "   \n",
    "    X_train = data[:500]\n",
    "    X_valid = data[500:]\n",
    "    \n",
    "    lr = ensemble.GradientBoostingRegressor() #Base Model\n",
    "    lr.fit(X_train[cols], X_train[target].values.ravel())\n",
    "    print (\"Base Score: \", lr.score(X_train[cols], X_train[target].values.ravel())) # 0.9672992360887501\n",
    "    best_score = 0\n",
    "    best_cols = cols\n",
    "    for k in range(len(cols)//4, len(cols)):\n",
    "        lr = ensemble.GradientBoostingRegressor()\n",
    "        curr_cols = select_cols(cols, target, X_train, k)\n",
    "        lr.fit(X_train[curr_cols], X_train[target].values.ravel())\n",
    "        os_score = lr.score(X_valid[curr_cols], X_valid[target].values.ravel())\n",
    "        if os_score > best_score:\n",
    "            is_score = lr.score(X_train[curr_cols], X_train[target].values.ravel())\n",
    "            print (\"K= \", k, \", IS score: \", is_score, \", OS score: \", os_score) # 0.840628507295174\n",
    "            best_score = os_score\n",
    "            best_cols = curr_cols\n",
    "            \n",
    "    return best_cols\n",
    "\n",
    "best_cols = find_best_cols(cols, \"Survived\", train)\n",
    "best_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(best_cols))\n",
    "print(len(cols))\n",
    "cols = best_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this function to save our results to CSV\n",
    "def save_results(model, data):\n",
    "    pred_test = model.predict(data)\n",
    "\n",
    "    #PassengerId,Survived\n",
    "    test_res = test[[\"PassengerId\"]].copy()\n",
    "    test_res[\"Survived\"] = pred_test\n",
    "    test_res.to_csv(\"my_predictions.csv\", index=False)\n",
    "    return test_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use this function to tune our model\n",
    "def get_tuned_model(estimator, param_grid, scoring, X_train, Y_train):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid = GridSearchCV(estimator = estimator, \n",
    "                       param_grid = param_grid,\n",
    "                       scoring = scoring,\n",
    "                       cv=3,\n",
    "                       n_jobs= -1\n",
    "                      )\n",
    "\n",
    "    tuned = grid.fit(X_train, Y_train)\n",
    "\n",
    "    print (\"Best score: \", tuned.best_score_) # 0.840628507295174\n",
    "    print (\"Best params: \", tuned.best_params_)\n",
    "    print (\"IS Score: \", tuned.score(X_train, Y_train)) # 0.8698092031425365\n",
    "    \n",
    "    return tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8305274971941637\n",
      "Best params:  {'C': 10, 'max_iter': 100, 'penalty': 'l2'}\n",
      "IS Score:  0.8451178451178452\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty': ['l1','l2'], \n",
    "              'C': [0.001,0.01,0.1,1,10,100],\n",
    "              'max_iter': [100,200,300,500]\n",
    "             }\n",
    "\n",
    "log_tuned = get_tuned_model(logit, param_grid, \"accuracy\", train[cols], train[['Survived']].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(log_tuned, test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8294051627384961\n",
      "Best params:  {'criterion': 'entropy', 'max_leaf_nodes': 16, 'min_samples_leaf': 1}\n",
      "IS Score:  0.8507295173961841\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    \"criterion\" : [\"gini\", \"entropy\"], \n",
    "    \"min_samples_leaf\" : [1, 5, 10], \n",
    "#     \"min_samples_split\" : [2, 4, 10, 12, 16],\n",
    "#     \"n_estimators\": n_estimators,\n",
    "    'max_leaf_nodes': range(4,20)\n",
    "}\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "ft_tuned = get_tuned_model(forest, param_grid, \"accuracy\", train[cols], train[['Survived']].values.ravel())\n",
    "# Best score:  0.8293955181721173\n",
    "# Best params:  {'criterion': 'gini', 'max_leaf_nodes': 14, 'min_samples_leaf': 1}\n",
    "# IS Score:  0.856341189674523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ft_tuned, test[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8372615039281706\n",
      "Best params:  {'learning_rate': 0.075, 'n_estimators': 400}\n",
      "IS Score:  0.9595959595959596\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    \"learning_rate\":  [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "    \"n_estimators\": [32, 64, 100, 200, 400, 500],\n",
    "}\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc_tuned = get_tuned_model(gbc, param_grid, \"accuracy\", train[cols], train[['Survived']].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(gbc_tuned, test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
